# Log 2026-01-14

## Summary of Changes
Today we focused on fixing the Gemini integration and improving the project structure to support GenUI testing.

### 1. Migration to Official SDK
- **Removed** `flutter_gemini` dependency.
- **Added** `google_generative_ai` (official SDK).
- **Updated** `GeminiModelImpl` to use `GenerativeModel`.
- **Implemented** `getModels` in `GeminiModelImpl` using the raw REST API (since the SDK doesn't expose listing models easily) to dynamic fetch available models for the user's API key.

### 2. Architecture & Navigation
- **Created** `DashboardPage` to act as a central hub (Navigation) between:
    - Main Chat (`ChatPage`)
    - GenUI Prototype (`GenUiTestPage`)
    - Settings (`SettingsPage`)
- **Updated** `main.dart` to use `DashboardPage` as the home screen.
- **Enhanced** `GenUiTestPage`:
    - Added a dropdown to select the model dynamically.
    - Added auto-fetching of models on init.
    - Added a refresh button to reload models.

### 3. Debugging Results
- The "403 Forbidden" error was resolved by using the official SDK and correct API key handling.
- The "Model not found" error for `gemini-1.5-flash` was resolved by implementing the dynamic model list, allowing the user to select a valid model for their region (e.g., `gemini-2.0-flash-exp` or `gemini-1.5-flash-latest`).
- **Current Blocker:** The LLM refused the request "Show me the prototype widgets" with "I am sorry, I am unable to fulfill that request."
    - **Root Cause:** The model lacks **context** and **tools**. It doesn't know it *can* generate UI, nor *how* to output the specific JSON/data structure required for GenUI.

## Next Steps: Agentic GenUI (Context & Tools)
The next session will focus on moving from raw API calls to an **Agentic Workflow**.

1.  **System Prompt & Context**:
    - Define a robust system prompt that establishes the "Agent" persona.
    - Provide context about the available GenUI components (tools).

2.  **Tool & Output Structure**:
    - **JSON Output**: Enforce a structured JSON output format for the model so it doesn't just chat, but returns data we can parse.
    - **Tool Definitions**: Define GenUI components (like `InfoCard`, `StatusBadge`) as "tools" the agent can call.
    - Instead of string matching (`COMPONENT_TRIGGER`), we will parse structured tool calls or JSON blocks to render the UI.

3.  **Future Vision**:
    - This "GenUI Agent" is the first step.
    - **MCP Servers**: In the future, tools will be provided by MCP (Model Context Protocol) servers.
    - **Multi-Agent**: We will integrate other specialist agents that can be called by the main assistant.

## Action Items for Next Session
- [ ] Design the `SystemPrompt` for the GenUI Agent.
- [ ] Define the JSON schema for GenUI component responses.
- [ ] Implement a JSON parser in `RealGenUiContentGenerator` to handle the agent's output.
- [ ] Test with the "Show me prototype widgets" prompt again, ensuring the agent uses the "tools" to construct the response.
